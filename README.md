# Tokenizer
Let's start Natural langauge processing from tokenizer 
As we all now tokenizer is base of NLP and there are different different kind of tokenizer
and all the people are usig it based on their purpose 
So lets Implemenation of all the tokenizer algorithm in python, i am not going to explain all theory in this
repo becuase you can find theory all over internet like huggingface or blogspost.
# Key Concepts
  1. write custome code for all tokenizer alogrithm
  2. Train custome tokenizer using Huggingface and sentencepiece
  3. Use pretrained tokenizer in huggingface and sentencepiece for inference

# type of tokenizers
There are mostly 4 type of tokenizer used in NLP
  1. character level tokenizer
  2. Byte pair Encoding(BPE) tokenizer
  3. word leve tokenzier
  4. sentence level tokenizer

In this repo i am going talk about first 3 tokenizer i.e character,BPE, word because sentence level tokenizer is not used mostly.

